<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Multi-level Single-linkage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for mlsl {nloptr}"><tr><td>mlsl {nloptr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Multi-level Single-linkage</h2>

<h3>Description</h3>

<p>The &ldquo;Multi-Level Single-Linkage&rdquo; (<acronym><span class="acronym">MLSL</span></acronym>) algorithm for global
optimization searches by a sequence of local optimizations from random
starting points. A modification of <acronym><span class="acronym">MLSL</span></acronym> is included using a
low-discrepancy sequence (<acronym><span class="acronym">LDS</span></acronym>) instead of pseudorandom numbers.
</p>


<h3>Usage</h3>

<pre>
mlsl(
  x0,
  fn,
  gr = NULL,
  lower,
  upper,
  local.method = "LBFGS",
  low.discrepancy = TRUE,
  nl.info = FALSE,
  control = list(),
  ...
)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x0</code></td>
<td>
<p>initial point for searching the optimum.</p>
</td></tr>
<tr valign="top"><td><code>fn</code></td>
<td>
<p>objective function that is to be minimized.</p>
</td></tr>
<tr valign="top"><td><code>gr</code></td>
<td>
<p>gradient of function <code>fn</code>; will be calculated numerically if
not specified.</p>
</td></tr>
<tr valign="top"><td><code>lower, upper</code></td>
<td>
<p>lower and upper bound constraints.</p>
</td></tr>
<tr valign="top"><td><code>local.method</code></td>
<td>
<p>only <code>BFGS</code> for the moment.</p>
</td></tr>
<tr valign="top"><td><code>low.discrepancy</code></td>
<td>
<p>logical; shall a low discrepancy variation be used.</p>
</td></tr>
<tr valign="top"><td><code>nl.info</code></td>
<td>
<p>logical; shall the original <acronym><span class="acronym">NLopt</span></acronym> info be shown.</p>
</td></tr>
<tr valign="top"><td><code>control</code></td>
<td>
<p>list of options, see <code>nl.opts</code> for help.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional arguments passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><acronym><span class="acronym">MLSL</span></acronym> is a &lsquo;multistart&rsquo; algorithm: it works by doing a
sequence of local optimizations&mdash;using some other local optimization
algorithm&mdash;from random or low-discrepancy starting points. MLSL is
distinguished, however, by a &lsquo;clustering&rsquo; heuristic that helps it to avoid
repeated searches of the same local optima and also has some theoretical
guarantees of finding all local optima in a finite number of local
minimizations.
</p>
<p>The local-search portion of <acronym><span class="acronym">MLSL</span></acronym> can use any of the other
algorithms in <acronym><span class="acronym">NLopt</span></acronym>, and, in particular, can use either
gradient-based or derivative-free algorithms. For this wrapper only
gradient-based <acronym><span class="acronym">LBFGS</span></acronym> is available as local method.
</p>


<h3>Value</h3>

<p>List with components:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>par</code></td>
<td>
<p>the optimal solution found so far.</p>
</td></tr>
<tr valign="top"><td><code>value</code></td>
<td>
<p>the function value corresponding to <code>par</code>.</p>
</td></tr>
<tr valign="top"><td><code>iter</code></td>
<td>
<p>number of (outer) iterations, see <code>maxeval</code>.</p>
</td></tr>
<tr valign="top"><td><code>convergence</code></td>
<td>
<p>integer code indicating successful completion (&gt; 0)
or a possible error number (&lt; 0).</p>
</td></tr>
<tr valign="top"><td><code>message</code></td>
<td>
<p>character string produced by <acronym><span class="acronym">NLopt</span></acronym> and giving
additional information.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If you don't set a stopping tolerance for your local-optimization
algorithm, <acronym><span class="acronym">MLSL</span></acronym> defaults to <code>ftol_rel = 1e-15</code> and
<code>xtol_rel = 1e-7</code> for the local searches.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers
</p>


<h3>References</h3>

<p>A. H. G. Rinnooy Kan and G. T. Timmer, &ldquo;Stochastic global
optimization methods&rdquo; Mathematical Programming, vol. 39, p. 27-78 (1987).
</p>
<p>Sergei Kucherenko and Yury Sytsko, &ldquo;Application of deterministic
low-discrepancy sequences in global optimization&rdquo;, Computational
Optimization and Applications, vol. 30, p. 297-318 (2005).
</p>


<h3>See Also</h3>

<p><code><a href="../../nloptr/help/direct.html">direct</a></code>
</p>


<h3>Examples</h3>

<pre>

## Minimize the Hartmann 6-Dimensional function
## See https://www.sfu.ca/~ssurjano/hart6.html

a &lt;- c(1.0, 1.2, 3.0, 3.2)
A &lt;- matrix(c(10,  0.05, 3, 17,
              3, 10, 3.5, 8,
              17, 17, 1.7, 0.05,
              3.5, 0.1, 10, 10,
              1.7, 8, 17, 0.1,
              8, 14, 8, 14), nrow = 4)

B  &lt;- matrix(c(.1312, .2329, .2348, .4047,
               .1696, .4135, .1451, .8828,
               .5569, .8307, .3522, .8732,
               .0124, .3736, .2883, .5743,
               .8283, .1004, .3047, .1091,
               .5886, .9991, .6650, .0381), nrow = 4)

hartmann6 &lt;- function(x, a, A, B) {
  fun &lt;- 0
  for (i in 1:4) {
    fun &lt;- fun - a[i] * exp(-sum(A[i, ] * (x - B[i, ]) ^ 2))
  }

  fun
}

## The function has a global minimum of -3.32237 at
## (0.20169, 0.150011, 0.476874, 0.275332, 0.311652, 0.6573)

S &lt;- mlsl(x0 = rep(0, 6), hartmann6, lower = rep(0, 6), upper = rep(1, 6),
      nl.info = TRUE, control = list(xtol_rel = 1e-8, maxeval = 1000),
      a = a, A = A, B = B)

</pre>

<hr /><div style="text-align: center;">[Package <em>nloptr</em> version 2.1.1 <a href="00Index.html">Index</a>]</div>
</div></body></html>
